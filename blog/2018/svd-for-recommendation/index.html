<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Creating a movie recommendation system | Dipesh Pandey</title> <meta name="author" content="Dipesh Pandey"> <meta name="description" content="Dipesh is a software engineer based in Norway. He likes to talk about indie projects and collaborating with other people on interesting projects. "> <meta name="keywords" content="python, javascript, norway, freelancer, contract, typescript, startup, fastapi, django, nodejs, aws, indiehacker, forex, automated trading, blockchain"> <meta property="og:site_name" content="Dipesh Pandey"> <meta property="og:type" content="website"> <meta property="og:title" content="Dipesh Pandey | Creating a movie recommendation system"> <meta property="og:url" content="https://dipespandey.github.io/blog/2018/svd-for-recommendation/"> <meta property="og:description" content="Dipesh is a software engineer based in Norway. He likes to talk about indie projects and collaborating with other people on interesting projects. "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Creating a movie recommendation system"> <meta name="twitter:description" content="Dipesh is a software engineer based in Norway. He likes to talk about indie projects and collaborating with other people on interesting projects. "> <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "Dipesh  Pandey"
        },
        "url": "https://dipespandey.github.io/blog/2018/svd-for-recommendation/",
        "@type": "WebSite",
        "description": "Dipesh is a software engineer based in Norway. He likes to talk about indie projects and collaborating with other people on interesting projects.
",
        "headline": "Creating a movie recommendation system",
        "sameAs": ["https://github.com/dipespandey", "https://telegram.me/dipeshpandey08", "https://www.linkedin.com/in/dipespandey", "https://discord.com/users/747835324931113090"],
        "name": "Dipesh  Pandey",
        "@context": "https://schema.org"
      }
    </script> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.google.com/download?family=Montserrat:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://dipespandey.github.io/blog/2018/svd-for-recommendation/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Dipesh </span>Pandey</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/models/">ML Models</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/reading/">Reading</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h3 class="post-title">Creating a movie recommendation system</h3> <p class="post-meta">January 4, 2018</p> <p class="post-tags">   ·   <a href="/blog/category/recommendation"> <i class="fas fa-tag fa-sm"></i> recommendation</a>   <a href="/blog/category/machine-learning"> <i class="fas fa-tag fa-sm"></i> machine-learning</a>   <a href="/blog/category/svd"> <i class="fas fa-tag fa-sm"></i> svd</a>   <a href="/blog/category/python"> <i class="fas fa-tag fa-sm"></i> python</a>   </p> </header> <article class="post-content"> <p>In my undergraduate degree, I built a movie recommendation system using Singular Value Decomposition (SVD). It was the first time I got to see the power of machine learning in action, and the results really surprised me in a good way.</p> <p>I will go through the process used in the project, and the code for this is available in my <a href="https://github.com/dipespandey/movie-recommendation-system" rel="external nofollow noopener" target="_blank">Github</a>.</p> <h3 id="data-collection">Data Collection</h3> <p>One of the most famous movie data APIs, Open Movie Database (OMDB) was used to get the movie data. The data was then stored in a CSV file. The data consists of 10000 movies and their corresponding ratings from 1000 users. Let’s take a look at the structure of the data.</p> <p>Let’s have a quick look at the data. While there are other files in the dataset, we will only be using the <code class="language-plaintext highlighter-rouge">u.data</code> file because it has all the ratings information we need.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user_id item_id rating timestamp
196	242	3	881250949
186	302	3	891717742
22	377	1	878887116
244	51	2	880606923
166	346	1	886397596
</code></pre></div></div> <h3 id="data-preprocessing">Data Preprocessing</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">random</span>


<span class="c1"># Load data from disk
</span><span class="k">def</span> <span class="nf">ratings_reader</span><span class="p">():</span>
   <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">user_id</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">item_id</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">]</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">dataset/u.data</span><span class="sh">'</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sh">'</span><span class="se">\t</span><span class="sh">'</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
   <span class="n">n_users</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">user_id</span><span class="p">.</span><span class="nf">unique</span><span class="p">().</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
   <span class="n">n_items</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">item_id</span><span class="p">.</span><span class="nf">unique</span><span class="p">().</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

   <span class="c1"># Create r_{ui}, our ratings matrix
</span>   <span class="n">ratings</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_users</span><span class="p">,</span> <span class="n">n_items</span><span class="p">))</span>
   <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="nf">itertuples</span><span class="p">():</span>
       <span class="n">ratings</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

   <span class="k">return</span> <span class="n">ratings</span>

<span class="n">ratings</span> <span class="o">=</span> <span class="nf">ratings_reader</span><span class="p">()</span>
<span class="n">n_users</span> <span class="o">=</span> <span class="n">ratings</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">n_items</span> <span class="o">=</span> <span class="n">ratings</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div> <h3 id="test-train-split">Test-Train Split</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_train_split</span><span class="p">(</span><span class="n">ratings</span><span class="p">):</span>
   <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">ratings</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
   <span class="n">train</span> <span class="o">=</span> <span class="n">ratings</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>

   <span class="k">for</span> <span class="n">user</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">ratings</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
      <span class="n">test_ratings</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">ratings</span><span class="p">[</span><span class="n">user</span><span class="p">,</span> <span class="p">:].</span><span class="nf">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
      <span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

      <span class="n">train</span><span class="p">[</span><span class="n">user</span><span class="p">,</span> <span class="n">test_ratings</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">test</span><span class="p">[</span><span class="n">user</span><span class="p">,</span> <span class="n">test_ratings</span><span class="p">]</span> <span class="o">=</span> <span class="n">ratings</span><span class="p">[</span><span class="n">user</span><span class="p">,</span> <span class="n">test_ratings</span><span class="p">]</span>

   <span class="nf">assert</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">all</span><span class="p">((</span><span class="n">train</span> <span class="o">*</span> <span class="n">test</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

   <span class="k">return</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>


<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="nf">test_train_split</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">get_rmse</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
   <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">actual</span><span class="p">.</span><span class="nf">nonzero</span><span class="p">()].</span><span class="nf">flatten</span><span class="p">()</span>
   <span class="n">actual</span> <span class="o">=</span> <span class="n">actual</span><span class="p">[</span><span class="n">actual</span><span class="p">.</span><span class="nf">nonzero</span><span class="p">()].</span><span class="nf">flatten</span><span class="p">()</span>
   <span class="n">mse</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span>
   <span class="k">return</span> <span class="n">mse</span><span class="o">**</span><span class="mf">0.5</span>
</code></pre></div></div> <h3 id="training-the-model">Training the model</h3> <h5 id="set-hyperparameters">Set hyperparameters</h5> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_iters</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">lmbda</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">k</span> <span class="o">=</span> <span class="mi">80</span>

<span class="n">users</span><span class="p">,</span> <span class="n">items</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="nf">nonzero</span><span class="p">()</span>

<span class="n">Bu</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">n_users</span><span class="p">)</span>
<span class="n">Bi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">n_items</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_users</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_items</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">global_bias</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">train</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)])</span>
<span class="n">train_rmses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_rmses</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></div> <h5 id="matrix-factorization-algorithm-for-collaborative-filtering">Matrix Factorization Algorithm for Collaborative Filtering</h5> <p>Before we start, let’s try to visualize how the algorithm works. The algorithm is called SVD (Singular Value Decomposition)-based Matrix Factorization. There’s a very intuitive video on youtube by <a href="https://www.youtube.com/@visualkernel" rel="external nofollow noopener" target="_blank">Visual Kernel</a> that explains the algorithm. Feel free to watch it.</p> <iframe width="720" height="500" style="width: 100%;" src="https://www.youtube.com/embed/vSczTbgc8Rc"> </iframe> <p>The following is a detailed breakdown of applying SVD to the given user-item matrix.<br> Consider the following user-item matrix:</p> <table class="table table-bordered"> <tr> <td>User</td> <td>Indiana Jones</td> <td>Star Wars</td> <td>Empire Strikes Back</td> <td>Incredibles</td> <td>Casablanca</td> </tr> <tr> <td>Bob</td> <td>4</td> <td>5</td> <td>?</td> <td>?</td> <td>?</td> </tr> <tr> <td>Ted</td> <td>?</td> <td>?</td> <td>?</td> <td>?</td> <td>1</td> </tr> <tr> <td>Ann</td> <td>?</td> <td>5</td> <td>5</td> <td>5</td> <td>?</td> </tr> </table> <p>Step 1: Initialize the User-Item Matrix ( R )</p> <ul> <li>Fill missing values with the average rating or zeros for simplicity:<br> \(R = \begin{bmatrix} 4 &amp; 5 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\ 0 &amp; 5 &amp; 5 &amp; 5 &amp; 0 \end{bmatrix}\)</li> </ul> <p>Step 2: Apply SVD</p> <ul> <li>Decompose \(R\) into three matrices \(U\), \(\Sigma\), and \(V^T\) such that \(R \approx U \Sigma V^T\).</li> </ul> <p>Example decomposition:</p> \[U = \begin{bmatrix} 0.58 &amp; 0.58 &amp; 0.58 \\ 0.29 &amp; -0.71 &amp; 0.65 \\ 0.76 &amp; -0.41 &amp; -0.50 \end{bmatrix}\] \[\Sigma = \begin{bmatrix} 9 &amp; 0 &amp; 0 \\ 0 &amp; 5 &amp; 0 \\ 0 &amp; 0 &amp; 2 \end{bmatrix}\] \[V^T = \begin{bmatrix} 0.58 &amp; 0.58 &amp; 0.58 &amp; 0.29 &amp; 0.29 \\ 0.29 &amp; -0.71 &amp; 0.65 &amp; 0.29 &amp; -0.29 \\ 0.76 &amp; -0.41 &amp; -0.50 &amp; 0.29 &amp; 0.29 \end{bmatrix}\] <p>Step 3: Reconstruct the Matrix</p> <ul> <li>Use the top \(k\) singular values to approximate \(R\): \(R' = U_k \Sigma_k V_k^T\)</li> </ul> <p>How does this work?</p> <ul> <li>The matrix \(R\) is decomposed into three matrices: \(U\), \(\Sigma\), and \(V^T\).</li> <li>\(U\) contains the left singular vectors, \(\Sigma\) is a diagonal matrix with singular values, and \(V^T\) contains the right singular vectors.</li> <li>By selecting the top \(k\) singular values, we reduce the dimensionality of the matrices while retaining the most significant features.</li> <li>The product of these reduced matrices \(U_k \Sigma_k V_k^T\) gives us an approximation of the original matrix \(R\), denoted as \(R'\).</li> <li>This approximation helps in reconstructing the matrix with reduced noise and improved generalization for predicting missing values.</li> </ul> <p>Step 4: Predict Missing Ratings</p> <ul> <li>Use the reconstructed matrix \(R'\) to fill in missing ratings: \(R' = \begin{bmatrix} 4 &amp; 5 &amp; 3 &amp; 2 &amp; 1 \\ 2 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\ 3 &amp; 5 &amp; 5 &amp; 5 &amp; 2 \end{bmatrix}\)</li> </ul> <p>The predicted ratings for missing values are derived from the reconstructed matrix \(R'\).</p> <p>Matrix Factorization is a collaborative filtering algorithm used to predict user-item interactions. The goal is to factorize the user-item interaction matrix into two lower-dimensional matrices, representing users and items, respectively. These matrices are then used to predict missing entries in the original matrix.</p> <p>Mathematically, we aim to decompose the user-item interaction matrix \(R\) into two matrices \(P\) and \(Q\) such that: \(R \approx P \cdot Q^T\)</p> <p>where:</p> <ul> <li>\(R\) is the \(n \times m\) user-item interaction matrix.</li> <li>\(P\) is the \(n \times k\) user-feature matrix.</li> <li>\(Q\) is the \(m \times k\) item-feature matrix.</li> <li>\(k\) is the number of latent features.</li> </ul> <p>The predicted rating \(\hat{r}_{ui}\) for user \(u\) and item \(i\) is given by:</p> \[\hat{r}_{ui} = P_u \cdot Q_i^T + B_u + B_i + \mu\] <p>where:</p> <ul> <li>\(P_u\) is the \(u\)-th row of matrix \(P\)</li> <li>\(Q_i\) is the \(i\)-th row of matrix \(Q\)</li> <li>\(B_u\) is the bias term for user \(u\)</li> <li>\(B_i\) is the bias term for item \(i\)</li> <li>\(\mu\) is the global bias term, representing the average rating.</li> </ul> <p>To learn the matrices \(P\) and \(Q\), we minimize the following regularized squared error loss function using Stochastic Gradient Descent (SGD):</p> \[\min_{P, Q, B_u, B_i} \sum_{(u,i) \in \mathcal{K}} \left( r_{ui} - \hat{r}_{ui} \right)^2 + \lambda \left( \|P_u\|^2 + \|Q_i\|^2 + B_u^2 + B_i^2 \right)\] <p>where:</p> <ul> <li>\(\mathcal{K}\) is the set of user-item pairs for which the ratings are known.</li> <li>\(\lambda\) is the regularization parameter to prevent overfitting.</li> </ul> <p>The update rules for SGD are as follows:</p> <p>\(P_u \leftarrow P_u + \gamma \left( e_{ui} \cdot Q_i - \lambda \cdot P_u \right)\)<br> \(Q_i \leftarrow Q_i + \gamma \left( e_{ui} \cdot P_u - \lambda \cdot Q_i \right)\)<br> \(B_u \leftarrow B_u + \gamma \left( e_{ui} - \lambda \cdot B_u \right)\)<br> \(B_i \leftarrow B_i + \gamma \left( e_{ui} - \lambda \cdot B_i \right)\)</p> <p>where:</p> <ul> <li>\(e_{ui} = r_{ui} - \hat{r}_{ui}\) is the prediction error.</li> <li>\(\gamma\) is the learning rate.</li> </ul> <p>By iteratively updating the matrices \(P\) and \(Q\), and the bias terms \(B_u\) and \(B_i\), we can minimize the loss function and obtain the optimal factorized matrices for predicting user-item interactions.</p> <p>Now, let’s implement the algorithm.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">trainer</span><span class="p">(</span><span class="n">n_iters</span><span class="p">,</span> <span class="n">users</span><span class="p">,</span> <span class="n">items</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Bu</span><span class="p">,</span> <span class="n">Bi</span><span class="p">,</span> <span class="n">global_bias</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">tester</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">lmbda</span><span class="p">):</span>
   <span class="c1"># use the stochastic gradient descent approach to mimimize the error in prediction
</span>   <span class="n">train_rmses</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="n">test_rmses</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_iters</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">users</span><span class="p">,</span> <span class="n">items</span><span class="p">):</span>
         <span class="n">prediction</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">u</span><span class="p">,:].</span><span class="nf">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">,:].</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">Bu</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">+</span> <span class="n">Bi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">global_bias</span>
         <span class="n">e</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">prediction</span>
         <span class="n">Bu</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">+=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">e</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">*</span> <span class="n">Bu</span><span class="p">[</span><span class="n">u</span><span class="p">])</span>
         <span class="n">Bi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">e</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">*</span> <span class="n">Bi</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
         <span class="n">P</span><span class="p">[</span><span class="n">u</span><span class="p">,:]</span> <span class="o">+=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">e</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">*</span> <span class="n">P</span><span class="p">[</span><span class="n">u</span><span class="p">,:])</span>
         <span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">+=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">e</span> <span class="o">*</span> <span class="n">P</span><span class="p">[</span><span class="n">u</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">lmbda</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
      
      <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">P</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

      <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">P</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">Q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">pred</span><span class="p">[</span><span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">u</span><span class="p">,:].</span><span class="nf">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">,:].</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">Bu</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">+</span> <span class="n">Bi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">global_bias</span>

      <span class="n">train_rmse</span> <span class="o">=</span> <span class="nf">get_rmse</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
      <span class="n">test_rmse</span> <span class="o">=</span> <span class="nf">get_rmse</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
      <span class="n">train_rmses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">train_rmse</span><span class="p">)</span>
      <span class="n">test_rmses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">test_rmse</span><span class="p">)</span>
      <span class="nf">print</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_rmse</span><span class="p">,</span> <span class="n">test_rmse</span><span class="p">)</span>
      <span class="nf">return</span><span class="p">(</span><span class="n">train_rmses</span><span class="p">,</span> <span class="n">test_rmses</span><span class="p">)</span>


<span class="c1"># Start training the model
</span><span class="n">train_rmses</span><span class="p">,</span> <span class="n">test_rmses</span> <span class="o">=</span> <span class="nf">trainer</span><span class="p">(</span><span class="n">n_iters</span><span class="p">,</span> <span class="n">users</span><span class="p">,</span> <span class="n">items</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Bu</span><span class="p">,</span> <span class="n">Bi</span><span class="p">,</span> <span class="n">global_bias</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">lmbda</span><span class="p">)</span>
</code></pre></div></div> <h3 id="plotting-the-learning-curves">Plotting the learning curves</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">draw_learning_curve</span><span class="p">(</span><span class="n">n_iters</span><span class="p">,</span> <span class="n">train_rmse</span><span class="p">,</span> <span class="n">test_rmse</span><span class="p">):</span>
   <span class="c1"># use this function to use the above train_rmses and test_rmses to plot the rmse curves, 
</span>   <span class="c1"># see how they converge
</span>   <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_iters</span><span class="p">),</span> <span class="n">train_rmse</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
   <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_iters</span><span class="p">),</span> <span class="n">test_rmse</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Test</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
   <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Iterations</span><span class="sh">'</span><span class="p">)</span>
   <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSE</span><span class="sh">'</span><span class="p">)</span>
   <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">best</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">Q</span><span class="p">):</span>
   <span class="c1"># finds the cosine similarity based on item feature matrix
</span>   <span class="c1"># parameter: Q ( item latent feature matrix)
</span>   <span class="n">sim</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
   <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">diagonal</span><span class="p">(</span><span class="n">sim</span><span class="p">))])</span>
   <span class="k">return</span> <span class="n">sim</span><span class="o">/</span> <span class="n">norms</span><span class="o">/</span> <span class="n">norms</span><span class="p">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">get_top_k</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="n">movie_id</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
   <span class="c1"># return the tuple of top k movies using the similarity matrix and movie_id
</span>   <span class="n">movie_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">sims</span><span class="p">[</span><span class="n">movie_id</span><span class="p">,:])[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
   <span class="n">top_k</span> <span class="o">=</span> <span class="n">movie_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">]</span>   
   <span class="n">top_k</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="n">top_k</span><span class="p">)</span>
   <span class="k">return</span> <span class="n">top_k</span>
</code></pre></div></div> <h3 id="inference">Inference</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">item_id</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Bu</span><span class="p">,</span> <span class="n">Bi</span><span class="p">,</span> <span class="n">global_bias</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Make a prediction for a given user and item using the trained matrices.
    
    Parameters:
    user_id (int): The ID of the user.
    item_id (int): The ID of the item.
    P (numpy array): User latent feature matrix.
    Q (numpy array): Item latent feature matrix.
    Bu (numpy array): User biases.
    Bi (numpy array): Item biases.
    global_bias (float): The global bias.
    
    Returns:
    float: The predicted rating.
    </span><span class="sh">"""</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">user_id</span><span class="p">,</span> <span class="p">:].</span><span class="nf">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">item_id</span><span class="p">,</span> <span class="p">:].</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">Bu</span><span class="p">[</span><span class="n">user_id</span><span class="p">]</span> <span class="o">+</span> <span class="n">Bi</span><span class="p">[</span><span class="n">item_id</span><span class="p">]</span> <span class="o">+</span> <span class="n">global_bias</span>
    <span class="k">return</span> <span class="n">prediction</span>

<span class="c1"># Example usage:
</span><span class="n">user_id</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># example user ID
</span><span class="n">item_id</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># example item ID
</span><span class="n">predicted_rating</span> <span class="o">=</span> <span class="nf">infer</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">item_id</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Bu</span><span class="p">,</span> <span class="n">Bi</span><span class="p">,</span> <span class="n">global_bias</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Predicted rating for user </span><span class="si">{</span><span class="n">user_id</span><span class="si">}</span><span class="s"> and item </span><span class="si">{</span><span class="n">item_id</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">predicted_rating</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>The fullstack project with the code is available <a href="https://github.com/Genalize/movieRecommendations" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>References:</p> <ul> <li>https://www.ethanrosenthal.com/2016/01/09/explicit-matrix-factorization-sgd-als/</li> <li>https://www.youtube.com/watch?v=vSczTbgc8Rc</li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Dipesh Pandey. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141259679-1"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-141259679-1");</script><script async type="text/javascript">!function(e,t,a,n,c,o,s){e.GoogleAnalyticsObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,o=t.createElement(a),s=t.getElementsByTagName(a)[0],o.async=1,o.src=n,s.parentNode.insertBefore(o,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-141259679-1","auto"),ga("send","pageview");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>